---
title: 确定 TiDB 规模
summary: 了解如何确定 TiDB Cloud 集群的规模。
---

# 确定 TiDB 规模

本文介绍如何确定 TiDB Cloud Dedicated 集群的规模。

> **注意：**
>
> 你无法更改 [TiDB Cloud Serverless](/tidb-cloud/select-cluster-tier.md#tidb-cloud-serverless) 集群的规模。

## TiDB 规模配置

TiDB 仅用于计算，不存储数据。它支持水平扩展。

你可以配置节点数量、vCPU 和内存。

要了解不同集群规模的性能测试结果，请参阅 [TiDB Cloud 性能参考](/tidb-cloud/tidb-cloud-performance-reference.md)。

### TiDB vCPU 和内存

支持的 vCPU 和内存规格包括：

| 标准规格 | 高内存规格 | 
|:---------:|:----------------:|
| 4 vCPU, 16 GiB  | 不适用          |
| 8 vCPU, 16 GiB    | 8 vCPU, 32 GiB        |
| 16 vCPU, 32 GiB  | 16 vCPU, 64 GiB         |
| 32 vCPU, 64 GiB   | 32 vCPU, 128 GiB        |

> **注意：**
>
> 要使用 **32 vCPU, 128 GiB** 规格的 TiDB，请联系 [TiDB Cloud 支持团队](/tidb-cloud/tidb-cloud-support.md)。
>
> 如果 TiDB 的 vCPU 和内存规格设置为 **4 vCPU, 16 GiB**，请注意以下限制：
>
> - TiDB 节点数量只能设置为 1 或 2，TiKV 节点数量固定为 3。
> - 4 vCPU TiDB 只能与 4 vCPU TiKV 一起使用。
> - TiFlash 不可用。

### TiDB 节点数量

为了实现高可用性，建议为每个 TiDB Cloud 集群配置至少两个 TiDB 节点。

通常，TiDB 性能随着 TiDB 节点数量的增加而线性增长。但是，当 TiDB 节点数量超过 8 个时，性能增长略低于线性比例。每增加 8 个节点，性能偏差系数约为 5%。

例如：

- 当有 9 个 TiDB 节点时，性能偏差系数约为 5%，因此 TiDB 性能约为单个 TiDB 节点性能的 `9 * (1 - 5%) = 8.55` 倍。
- 当有 16 个 TiDB 节点时，性能偏差系数约为 10%，因此 TiDB 性能为单个 TiDB 节点性能的 `16 * (1 - 10%) = 14.4` 倍。

对于 TiDB 节点的指定延迟，TiDB 性能会根据不同的读写比例而变化。

8 vCPU, 16 GiB TiDB 节点在不同工作负载下的性能如下：

| 工作负载 | QPS (P95 ≈ 100ms) | QPS (P99 ≈ 300ms) | QPS (P99 ≈ 100ms) |
|----------|-------------------|-------------------|-------------------|
| 读取     | 18,900            | 9,450             | 6,300             |
| 混合    | 15,500            | 7,750             | 5,200             |
| 写入    | 18,000            | 9,000             | 6,000             |

如果 TiDB 节点数量少于 8 个，性能偏差系数接近 0%，因此 16 vCPU, 32 GiB TiDB 节点的性能大约是 8 vCPU, 16 GiB TiDB 节点的两倍。如果 TiDB 节点数量超过 8 个，建议选择 16 vCPU, 32 GiB TiDB 节点，因为这样需要的节点更少，意味着性能偏差系数更小。

在规划集群规模时，你可以根据工作负载类型、整体期望性能（QPS）以及单个 TiDB 节点对应工作负载类型的性能，使用以下公式估算 TiDB 节点数量：

`节点数量 = ceil(整体期望性能 ÷ 每节点性能 * (1 - 性能偏差系数))`

在公式中，你需要先计算 `节点数量 = ceil(整体期望性能 ÷ 每节点性能)` 得到一个粗略的节点数量，然后使用相应的性能偏差系数得到最终的节点数量。

例如，你在混合工作负载下的整体期望性能是 110,000 QPS，P95 延迟约为 100 ms，并且你想使用 8 vCPU, 16 GiB TiDB 节点。那么，你可以从前面的表格中获取 8 vCPU, 16 GiB TiDB 节点的估计 TiDB 性能（即 `15,500`），并计算粗略的 TiDB 节点数量如下：

`节点数量 = ceil(110,000 ÷ 15,500) = 8`

由于 8 个节点的性能偏差系数约为 5%，估计的 TiDB 性能为 `8 * 15,500 * (1 - 5%) = 117,800`，可以满足你期望的 110,000 QPS 性能。

因此，建议你使用 8 个 TiDB 节点（8 vCPU, 16 GiB）。

## TiKV 规模配置

TiKV 负责存储数据。它支持水平扩展。

你可以配置节点数量、vCPU 和内存以及存储。

要了解不同集群规模的性能测试结果，请参阅 [TiDB Cloud 性能参考](/tidb-cloud/tidb-cloud-performance-reference.md)。

### TiKV vCPU 和内存

支持的 vCPU 和内存规格包括：

| 标准规格 | 高内存规格 | 
|:---------:|:----------------:|
| 4 vCPU, 16 GiB  |  不适用        |
| 8 vCPU, 32 GiB    | 8 vCPU, 64 GiB        |
| 16 vCPU, 64 GiB  | 即将推出       |
| 32 vCPU, 128 GiB   |  不适用  |

> **注意：**
>
> 如果 TiKV 的 vCPU 和内存规格设置为 **4 vCPU, 16 GiB**，请注意以下限制：
>
> - TiDB 节点数量只能设置为 1 或 2，TiKV 节点数量固定为 3。
> - 4 vCPU TiKV 只能与 4 vCPU TiDB 一起使用。
> - TiFlash 不可用。

### TiKV 节点数量

TiKV 节点数量应该**至少为 1 组（3 个节点分布在 3 个不同的可用区）**。

TiDB Cloud 将 TiKV 节点均匀部署到你选择的区域中的所有可用区（至少 3 个）以实现持久性和高可用性。在典型的 3 副本设置中，你的数据均匀分布在所有可用区的 TiKV 节点中，并持久化到每个 TiKV 节点的磁盘上。

> **注意：**
>
> 当你扩展 TiDB 集群时，3 个可用区中的节点会同时增加或减少。有关如何根据需求扩容或缩容 TiDB 集群，请参阅[扩展 TiDB 集群](/tidb-cloud/scale-tidb-cluster.md)。

虽然 TiKV 主要用于数据存储，但 TiKV 节点的性能也会根据不同的工作负载而变化。因此，在规划 TiKV 节点数量时，你需要根据[**数据量**](#根据数据量估算-tikv-节点数量)和[期望性能](#根据期望性能估算-tikv-节点数量)进行估算，然后取两个估算值中的较大者作为推荐的节点数量。

#### 根据数据量估算 TiKV 节点数量

你可以根据数据量按以下方式计算推荐的 TiKV 节点数量：

`节点数量 = ceil(数据大小 * TiKV 压缩比 * 副本数量 ÷ TiKV 存储使用率 ÷ 单个 TiKV 容量 ÷ 3) * 3`

通常，建议将 TiKV 存储使用率保持在 80% 以下。TiDB Cloud 中的副本数量默认为 3。8 vCPU, 64 GiB TiKV 节点的最大存储容量为 4096 GiB。

根据历史数据，平均 TiKV 压缩比约为 40%。

假设你的 MySQL 转储文件大小为 20 TB，TiKV 压缩比为 40%。那么，你可以根据数据量按以下方式计算推荐的 TiKV 节点数量：

`节点数量 = ceil(20 TB * 40% * 3 ÷ 0.8 ÷ 4096 GiB ÷ 3) * 3 = 9`

#### 根据期望性能估算 TiKV 节点数量

与 TiDB 性能类似，TiKV 性能随着 TiKV 节点数量的增加而线性增长。但是，当 TiKV 节点数量超过 8 个时，性能增长略低于线性比例。每增加 8 个节点，性能偏差系数约为 5%。

例如：

- 当有 9 个 TiKV 节点时，性能偏差系数约为 5%，因此 TiKV 性能约为单个 TiKV 节点性能的 `9 * (1 - 5%) = 8.55` 倍。
- 当有 18 个 TiKV 节点时，性能偏差系数约为 10%，因此 TiKV 性能为单个 TiKV 节点性能的 `18 * (1 - 10%) = 16.2` 倍。

对于 TiKV 节点的指定延迟，TiKV 性能会根据不同的读写比例而变化。

8 vCPU, 32 GiB TiKV 节点在不同工作负载下的性能如下：

| 工作负载 | QPS (P95 ≈ 100ms) | QPS (P99 ≈ 300ms) | QPS (P99 ≈ 100ms) |
|----------|-------------------|-------------------|-------------------|
| 读取     | 28,000            | 14,000            | 7,000             |
| 混合    | 17,800            | 8,900             | 4,450             |
| 写入    | 14,500            | 7,250             | 3,625             |

如果 TiKV 节点数量少于 8 个，性能偏差系数接近 0%，因此 16 vCPU, 64 GiB TiKV 节点的性能大约是 8 vCPU, 32 GiB TiKV 节点的两倍。如果 TiKV 节点数量超过 8 个，建议选择 16 vCPU, 64 GiB TiKV 节点，因为这样需要的节点更少，意味着性能偏差系数更小。

在规划集群规模时，你可以根据工作负载类型、整体期望性能（QPS）以及单个 TiKV 节点对应工作负载类型的性能，使用以下公式估算 TiKV 节点数量：

`节点数量 = ceil(整体期望性能 ÷ 每节点性能 * (1 - 性能偏差系数))`

在公式中，你需要先计算 `节点数量 = ceil(整体期望性能 ÷ 每节点性能)` 得到一个粗略的节点数量，然后使用相应的性能偏差系数得到最终的节点数量。

例如，你在混合工作负载下的整体期望性能是 110,000 QPS，P95 延迟约为 100 ms，并且你想使用 8 vCPU, 32 GiB TiKV 节点。那么，你可以从前面的表格中获取 8 vCPU, 32 GiB TiKV 节点的估计 TiKV 性能（即 `17,800`），并计算粗略的 TiKV 节点数量如下：

`节点数量 = ceil(110,000 / 17,800 ) = 7`

由于 7 小于 8，7 个节点的性能偏差系数为 0。估计的 TiKV 性能为 `7 * 17,800 * (1 - 0) = 124,600`，可以满足你期望的 110,000 QPS 性能。

因此，根据你的期望性能，建议使用 7 个 TiKV 节点（8 vCPU, 32 GiB）。

接下来，你可以比较根据数据量计算的 TiKV 节点数量与根据期望性能计算的数量，取较大者作为推荐的 TiKV 节点数量。

### TiKV 节点存储大小

不同 TiKV vCPU 支持的节点存储大小如下：

| TiKV vCPU | 最小节点存储 | 最大节点存储 | 默认节点存储 |
|:---------:|:----------------:|:----------------:|:--------------------:|
| 4 vCPU    | 200 GiB          |     2048 GiB     | 500 GiB              |
| 8 vCPU    | 200 GiB          |     4096 GiB     | 500 GiB              |
| 16 vCPU   | 200 GiB          |     4096 GiB     | 500 GiB              |
| 32 vCPU   | 200 GiB          |     4096 GiB     | 500 GiB              |

> **注意：**
>
> 集群创建后，你无法减少 TiKV 节点存储大小。

### TiKV 节点存储类型

TiDB Cloud 为在 AWS 上托管的 [TiDB Cloud Dedicated](/tidb-cloud/select-cluster-tier.md#tidb-cloud-dedicated) 集群提供以下 TiKV 存储类型：

- [基础存储](#基础存储)
- [标准存储](#标准存储)
- [性能和增强存储](#性能和增强存储)

#### 基础存储

基础存储是一种通用存储类型，性能低于标准存储。

基础存储类型自动应用于以下在 AWS 上托管的集群：

- 在 2025 年 4 月 1 日之前创建的现有集群。
- 使用早于 v7.5.5、v8.1.2 或 v8.5.0 版本的 TiDB 创建的新集群。

#### 标准存储

标准存储适用于大多数工作负载，在性能和成本效益之间取得平衡。与基础存储相比，它通过为 Raft 日志保留充足的磁盘资源提供更好的性能。这减少了 Raft I/O 对数据磁盘 I/O 的影响，提高了 TiKV 的读写性能。

标准存储类型自动应用于在 AWS 上托管的、使用 TiDB v7.5.5、v8.1.2、v8.5.0 或更高版本创建的新集群。

#### 性能和增强存储

性能和增强存储提供更高的性能和稳定性，价格反映了这些增强的功能。目前，这两种存储类型仅在申请后可用于在 AWS 上部署的集群。要申请性能或增强存储，请点击 [TiDB Cloud 控制台](https://tidbcloud.com)右下角的 **?**，然后点击**请求支持**。然后，在**描述**字段中填写"申请 TiKV 存储类型"，并点击**提交**。

## TiFlash 规模配置

TiFlash 实时从 TiKV 同步数据，并支持开箱即用的实时分析工作负载。它支持水平扩展。

你可以配置节点数量、vCPU 和内存以及存储。

### TiFlash vCPU 和内存

支持的 vCPU 和内存规格包括：

- 8 vCPU, 64 GiB
- 16 vCPU, 128 GiB
- 32 vCPU, 128 GiB
- 32 vCPU, 256 GiB

注意，当 TiDB 或 TiKV 的 vCPU 和内存规格设置为 **4 vCPU, 16 GiB** 时，TiFlash 不可用。

### TiFlash 节点数量

TiDB Cloud 将 TiFlash 节点均匀部署到区域中的不同可用区。建议在每个 TiDB Cloud 集群中配置至少两个 TiFlash 节点，并在生产环境中为数据创建至少两个副本以实现高可用性。

TiFlash 节点的最小数量取决于特定表的 TiFlash 副本数量：

TiFlash 节点最小数量：`min((表 A 的压缩大小 * 表 A 的副本数 + 表 B 的压缩大小 * 表 B 的副本数) / 每个 TiFlash 容量大小, max(表 A 的副本数, 表 B 的副本数))`

例如，如果你在 AWS 上将每个 TiFlash 节点的存储配置为 1024 GiB，并为表 A（压缩大小为 800 GiB）设置 2 个副本，为表 B（压缩大小为 100 GiB）设置 1 个副本，那么所需的 TiFlash 节点数量如下：

TiFlash 节点最小数量：`min((800 GiB * 2 + 100 GiB * 1) / 1024 GiB, max(2, 1)) ≈ 2`

### TiFlash 节点存储

不同 TiFlash vCPU 支持的节点存储如下：

| TiFlash vCPU | 最小节点存储 | 最大节点存储 | 默认节点存储 |
|:---------:|:----------------:|:----------------:|:--------------------:|
| 8 vCPU    | 200 GiB          | 4096 GiB         | 500 GiB              |
| 16 vCPU   | 200 GiB          | 4096 GiB         | 500 GiB              |
| 32 vCPU   | 200 GiB          | 8192 GiB         | 500 GiB              |

> **注意：**
>
> 集群创建后，你无法减少 TiFlash 节点存储。

### TiFlash 节点存储类型

TiDB Cloud 为在 AWS 上托管的 [TiDB Cloud Dedicated](/tidb-cloud/select-cluster-tier.md#tidb-cloud-dedicated) 集群提供以下 TiFlash 存储类型：

- [基础存储](#基础存储-1)
- [增强存储](#增强存储)

#### 基础存储

基础存储适用于大多数工作负载，在性能和成本效益之间取得平衡。

#### 增强存储

增强存储提供更高的性能和稳定性，价格反映了这些增强的功能。目前，此存储类型仅在申请后可用于在 AWS 上部署的集群。要申请它，请点击 [TiDB Cloud 控制台](https://tidbcloud.com)右下角的 **?**，然后点击**请求支持**。然后，在**描述**字段中填写"申请 TiFlash 存储类型"，并点击**提交**。
