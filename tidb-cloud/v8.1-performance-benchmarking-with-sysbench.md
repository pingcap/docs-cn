---
title: TiDB Cloud v8.1.0 版本 Sysbench 性能测试报告
summary: 介绍 TiDB v8.1.0 版本的 TiDB Cloud Dedicated 集群的 Sysbench 性能测试结果。
---

# TiDB Cloud v8.1.0 版本 Sysbench 性能测试报告

本文提供了 TiDB v8.1.0 版本的 TiDB Cloud Dedicated 集群的 Sysbench 性能测试步骤和结果。本报告也可以作为 TiDB 自托管 v8.1.0 集群性能的参考。

## 测试概述

本测试旨在展示 TiDB v8.1.0 在在线事务处理（OLTP）场景下的 Sysbench 性能。

## 测试环境

### TiDB 集群

测试在具有以下设置的 TiDB 集群上进行：

- 集群类型：[TiDB Cloud Dedicated](/tidb-cloud/select-cluster-tier.md#tidb-cloud-dedicated)
- 集群版本：v8.1.0
- 云服务提供商：AWS (us-west-2)
- 集群配置：

    | 节点类型 | 节点规格 | 节点数量 | 节点存储 |
    |:----------|:----------|:----------|:----------|
    | TiDB      | 16 vCPU, 32 GiB | 2 | N/A |
    | TiKV      | 16 vCPU, 64 GiB | 3 | 1000 GiB |

### 参数配置

系统变量 [`tidb_session_plan_cache_size`](https://docs.pingcap.com/tidb/stable/system-variables#tidb_session_plan_cache_size-new-in-v710) 控制可以缓存的计划的最大数量。默认值为 `100`。对于每个工作负载，本文在将 `tidb_session_plan_cache_size` 设置为 `1000` 的情况下进行测试：

```sql
SET GLOBAL tidb_session_plan_cache_size = 1000;
```

> **注意：**
>
> 对于 TiDB Cloud，如果要修改集群的 TiKV 参数，你可以联系 [PingCAP 支持团队](/tidb-cloud/tidb-cloud-support.md)寻求帮助。

TiKV 参数 [`prefill-for-recycle`](https://docs.pingcap.com/tidb/stable/tikv-configuration-file#prefill-for-recycle-new-in-v700) 可以使日志回收在初始化后立即生效。本文基于不同的工作负载，使用以下 `prefill-for-recycle` 配置进行测试：

- 对于 `oltp_point_select` 工作负载，使用 [`prefill-for-recycle`](https://docs.pingcap.com/tidb/stable/tikv-configuration-file#prefill-for-recycle-new-in-v700) 参数的默认值：

    ```yaml
    raft-engine.prefill-for-recycle = false
    ```

- 对于 `oltp_insert`、`oltp_read_write`、`oltp_update_index` 和 `oltp_update_non_index` 工作负载，启用 [`prefill-for-recycle`](https://docs.pingcap.com/tidb/stable/tikv-configuration-file#prefill-for-recycle-new-in-v700) 参数：

    ```yaml
    raft-engine.prefill-for-recycle = true
    ```

### 基准测试执行器

基准测试执行器向 TiDB 集群发送 SQL 查询。在本测试中，其硬件配置如下：

- 机器类型：Amazon EC2 (us-west-2)
- 实例类型：c6a.2xlarge
- Sysbench 版本：sysbench 1.0.20（使用捆绑的 LuaJIT 2.1.0-beta2）

## 测试步骤

本节介绍如何逐步执行 Sysbench 性能测试。

1. 在 [TiDB Cloud 控制台](https://tidbcloud.com/)中，创建一个满足[测试环境](#tidb-集群)要求的 TiDB Cloud Dedicated 集群。

    更多信息，请参见[创建 TiDB Cloud Dedicated 集群](/tidb-cloud/create-tidb-cluster.md)。

2. 在基准测试执行器上，连接到新创建的集群并创建名为 `sbtest` 的数据库。

    要连接到集群，请参见[通过私有端点连接到 TiDB Cloud Dedicated](/tidb-cloud/set-up-private-endpoint-connections.md)。

    要创建 `sbtest` 数据库，执行以下 SQL 语句：

    ```sql
    CREATE DATABASE sbtest;
    ```

3. 将 Sysbench 数据加载到 `sbtest` 数据库。

    1. 本文中的测试基于 [sysbench](https://github.com/akopytov/sysbench) 实现。要安装 sysbench，请参见[从源代码构建和安装](https://github.com/akopytov/sysbench#building-and-installing-from-source)。

    2. 运行以下 `sysbench prepare` 命令，向 `sbtest` 数据库导入 32 个表和 10,000,000 行数据。将 `${HOST}`、`${PORT}`、`${THREAD}` 和 `${PASSWORD}` 替换为你的实际值。

      ```shell
      sysbench oltp_common \
         --threads=${THREAD} \
         --db-driver=mysql \
         --mysql-db=sbtest \
         --mysql-host=${HOST} \
         --mysql-port=${PORT} \
         --mysql-user=root \
         --mysql-password=${PASSWORD} \
         prepare --tables=32 --table-size=10000000
      ```

4. 运行以下 `sysbench run` 命令，对不同的工作负载进行 Sysbench 性能测试。本文对五个工作负载进行测试：`oltp_point_select`、`oltp_read_write`、`oltp_update_non_index`、`oltp_update_index` 和 `oltp_insert`。对于每个工作负载，本文使用不同的 `${THREAD}` 变量值进行三次测试。对于 `oltp_point_select` 和 `oltp_read_write`，值分别为 `50`、`100` 和 `200`。对于其他工作负载，值分别为 `100`、`200` 和 `400`。每个并发测试持续 20 分钟。

    ```shell
    sysbench ${WORKLOAD} run \
      --mysql-host=${HOST} \
      --mysql-port=${PORT} \
      --mysql-user=root \
      --db-driver=mysql \
      --mysql-db=sbtest \
      --threads=${THREAD} \
      --time=1200 \
      --report-interval=10 \
      --tables=32 \
      --table-size=10000000 \
      --mysql-ignore-errors=1062,2013,8028,9007 \
      --auto-inc=false \
      --mysql-password=${PASSWORD}
    ```

## 测试结果

本节介绍 v8.1.0 在[测试环境](#测试环境)中的 Sysbench 性能。

### 点查询性能

`oltp_point_select` 工作负载的性能如下：

| 线程数 |  TPS | 95% 延迟 (ms)|
|:--------|:----------|:----------|
| 50 | 32,741  | 1.96 |
| 100 | 62,545 | 2.03 |
| 200 | 111,470 | 2.48 |

![Sysbench 点查询性能](/media/tidb-cloud/v8.1.0_oltp_point_select.png)

### 读写性能

`oltp_read_write` 工作负载的性能如下：

| 线程数 |  TPS | 95% 延迟 (ms)|
|:--------|:----------|:----------|
| 50 | 1,232 | 46.6 |
| 100 | 2,341 | 51 |
| 200 | 3,240 | 109  |

![Sysbench 读写性能](/media/tidb-cloud/v8.1.0_oltp_read_write.png)

### 更新非索引性能

`oltp_update_non_index` 工作负载的性能如下：

| 线程数 |  TPS | 95% 延迟 (ms)|
|:--------|:----------|:----------|
| 100 | 14,000  | 9.39 |
| 200 | 25,215  | 10.5 |
| 400 | 42,550  | 12.8 |

![Sysbench 更新非索引性能](/media/tidb-cloud/v8.1.0_oltp_update_non_index.png)

### 更新索引性能

`oltp_update_index` 工作负载的性能如下：

| 线程数 |  TPS | 95% 延迟 (ms)|
|:--------|:----------|:----------|
| 100 | 11,188   | 11.7 |
| 200 | 17,805  | 14.7 |
| 400 | 24,575  | 23.5 |

![Sysbench 更新索引性能](/media/tidb-cloud/v8.1.0_oltp_update_index.png)

### 插入性能

`oltp_insert` 工作负载的性能如下：

| 线程数 |  TPS | 95% 延迟 (ms)|
|:--------|:----------|:----------|
| 100 | 18,339  | 7.3|
| 200 | 29,387  | 9.73 |
| 400 | 42,712  | 14.2 |

![Sysbench 插入性能](/media/tidb-cloud/v8.1.0_oltp_insert.png)
