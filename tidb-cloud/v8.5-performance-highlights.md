---
title: TiDB v8.5.0 版本的 TiDB Cloud 性能亮点
summary: 介绍 TiDB v8.5.0 版本的 TiDB Cloud Dedicated 集群的性能改进。
---

# TiDB v8.5.0 版本的 TiDB Cloud 性能亮点

[TiDB v8.5.0](https://docs.pingcap.com/tidb/v8.5/release-8.5.0) 是一个重要的长期支持（LTS）版本，在性能、可扩展性和运维效率方面都有显著改进。

本文概述了 v8.5.0 在以下方面的性能改进：

- 整体性能
- 具有大量 MVCC 版本的热点读取
- IO 延迟抖动
- 批处理
- TiKV 扩展性能

## 整体性能

在 v8.5.0 中，默认 Region 大小从 96 MiB 增加到 256 MiB，并且还有其他一些改进，观察到显著的性能提升：

- `oltp_insert` 性能提升 27%。
- `Analyze` 性能显著提升约 45%。

## 具有大量 MVCC 版本的热点读取

### 挑战

在某些用户场景中，可能会出现以下挑战：

- 频繁的版本更新：在某些工作负载中，数据被非常频繁地更新和读取。
- 历史版本保留时间长：为了满足业务需求，如支持回退到特定时间点，用户可能会配置过长的 GC（垃圾回收）时间（如 24 小时）。这导致多版本并发控制（MVCC）版本过度累积，显著降低查询效率。

MVCC 版本的累积在请求的数据和处理的数据之间创造了巨大的差距，导致读取性能下降。

### 解决方案

为了解决这个问题，TiKV 引入了[内存引擎（IME）](https://docs.pingcap.com/tidb/stable/tikv-in-memory-engine)。通过在内存中缓存最新版本，TiKV 减少了历史版本对读取性能的影响，显著提高了查询效率。

### 测试环境

- 集群拓扑：TiDB（16 vCPU，32 GiB）\* 1 + TiKV（16 vCPU，32 GiB）\* 6
- 集群配置：

    ```
    tikv_configs:
    [in-memory-engine]
    enable = true
    ```

- 数据集：24 GiB 存储大小，约 340 个 Region，包含频繁更新的数据
- 工作负载：需要扫描的行包含由频繁更新引入的大量 MVCC 版本

### 测试结果

查询延迟降低 50%，吞吐量提高 100%。

| 配置 | 持续时间（秒） | 线程数 | TPS | QPS | 平均延迟（毫秒） | P95 延迟（毫秒） |
| --- |  --- |  --- |  --- |  --- |  --- |  --- |
| 禁用 IME | 3600 | 10 | 123.8 | 1498.3 | 80.76 | 207.82 |
| 启用 IME | 3600 | 10 | 238.2 | 2881.5 | 41.99 | 78.60 |

## IO 延迟抖动

### 挑战

在云环境中，云盘上的瞬时或持续的 IO 延迟波动是一个常见的挑战。这些波动会增加请求延迟，导致超时、错误和正常业务运营中断，最终降低服务质量。

### 解决方案

TiDB v8.5.0 引入了多项增强功能，以减轻云盘 IO 抖动对性能的影响：

- **Leader 写入优化**：允许 leader 提前应用已提交但尚未持久化的 Raft 日志，减少 IO 抖动对 leader peer 写入延迟的影响。
- **增强的慢节点检测**：改进了慢节点检测算法，默认启用慢分数检测。当识别到慢节点时，触发 evict-leader 调度器以恢复性能。[慢节点检测机制](https://docs.pingcap.com/tidb/v8.5/pd-scheduling-best-practices#troubleshoot-tikv-node)使用 [evict-slow-store-scheduler](https://docs.pingcap.com/tidb/v8.5/pd-control#scheduler-show--add--remove--pause--resume--config--describe) 来检测和管理慢节点，减少云盘抖动的影响。

- **统一健康控制器**：在 TiKV 中添加统一健康控制器，并向 KV 客户端提供反馈机制。KV 客户端根据 TiKV 节点的健康状况和性能优化错误处理和副本选择。
- **改进的副本选择器**：在 KV 客户端中引入副本选择器 V2，具有精细的状态转换，消除不必要的重试和退避操作。
- **其他修复和改进**：包括对关键组件（如 region 缓存和 KV 客户端健康检查器）的增强，同时避免 TiKV 的 store 循环中不必要的 IO 操作。

### 测试环境

- 集群拓扑：TiDB（32 vCPU，64 GiB）\* 3 + TiKV（32 vCPU，64 GiB）\* 6
- 工作负载：读写比为 2:1，在一个 TiKV 节点上模拟云盘 IO 延迟或挂起

### 测试结果

基于上述测试设置，在多个 IO 延迟场景中故障转移得到改进，影响期间的 P99/999 延迟最高降低 98%。

在下表的测试结果中，**当前**列显示减少 IO 延迟抖动改进后的结果，而**原始**列显示没有这些改进的结果：

<table>
    <thead>
        <tr>
            <th rowspan="2">工作负载描述</th>
            <th colspan="2">故障转移时间</th>
            <th colspan="2">影响期间最大延迟（P999）</th>
            <th colspan="2">影响期间最大延迟（P99）</th>
        </tr>
        <tr>
            <th>当前</th>
            <th>原始</th>
            <th>当前</th>
            <th>原始</th>
            <th>当前</th>
            <th>原始</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>IO 延迟 2 毫秒持续 10 分钟</td>
            <td>几乎无影响</td>
            <td>无法故障转移</td>
            <td>14 毫秒</td>
            <td>232 毫秒</td>
            <td>7.9 毫秒</td>
            <td>22.9 毫秒</td>
        </tr>
        <tr>
            <td>IO 延迟 5 毫秒持续 10 分钟</td>
            <td>2 分钟</td>
            <td>无法故障转移</td>
            <td>37.9 毫秒</td>
            <td>462 毫秒</td>
            <td>10 毫秒</td>
            <td>246 毫秒</td>
        </tr>
        <tr>
            <td>IO 延迟 10 毫秒持续 10 分钟</td>
            <td>3 分钟</td>
            <td>无法故障转移</td>
            <td>69 毫秒</td>
            <td>3 秒</td>
            <td>25 毫秒</td>
            <td>1.45 秒</td>
        </tr>
        <tr>
            <td>IO 延迟 50 毫秒持续 10 分钟</td>
            <td>3 分钟</td>
            <td>无法故障转移</td>
            <td>1.36 秒</td>
            <td>13.2 秒</td>
            <td>238 毫秒</td>
            <td>6.7 秒</td>
        </tr>
        <tr>
            <td>IO 延迟 100 毫秒持续 10 分钟</td>
            <td>3 分钟</td>
            <td>无法故障转移</td>
            <td>7.53 秒</td>
            <td>32 秒</td>
            <td>1.7 秒</td>
            <td>26 秒</td>
        </tr>
    </tbody>
</table>

### 进一步改进

磁盘抖动的严重程度可能与用户的工作负载特征高度相关。在对延迟敏感的场景中，将应用程序设计与 TiDB 功能结合可以进一步最小化 IO 抖动对应用程序的影响。例如，在读取密集且对延迟敏感的环境中，根据延迟要求调整 [`tikv_client_read_timeout`](/system-variables.md#tikv_client_read_timeout-new-in-v740) 系统变量，并使用 stale read 或 follower read，可以使从 TiDB 发送的 KV 请求更快地故障转移到其他副本节点。这减少了单个 TiKV 节点上 IO 抖动的影响，有助于改善查询延迟。请注意，此功能的有效性取决于工作负载特征，应在实施前进行评估。

此外，[在公有云上部署 TiDB](https://docs.pingcap.com/tidb/dev/best-practices-on-public-cloud) 的用户可以通过选择性能更高的云盘来降低抖动的概率。

## 批处理

### 挑战

大规模事务，如批量数据更新、系统迁移和 ETL 工作流，涉及处理数百万行数据，对支持关键操作至关重要。虽然 TiDB 作为分布式 SQL 数据库表现出色，但大规模处理此类事务面临两个重大挑战：

- 内存限制：在早于 TiDB v8.1.0 的版本中，所有事务变更在整个事务生命周期中都保存在内存中，这会消耗资源并降低性能。对于涉及数百万行的操作，这可能导致过度的内存使用，在资源不足时甚至可能出现内存溢出（OOM）错误。

- 性能下降：管理大型内存缓冲区依赖于红黑树，这会引入计算开销。随着缓冲区增长，由于这些数据结构固有的 *O(N log N)* 复杂度，其操作会变慢。

### 解决方案

这些挑战突显了提高可扩展性、降低复杂性和增强可靠性的明确机会。随着现代数据工作负载的增加，TiDB 引入了[流水线 DML](https://docs.pingcap.com/tidb/stable/system-variables#tidb_dml_type-new-in-v800) 功能，旨在优化大型事务的处理，提高资源利用率和整体性能。

### 测试环境

- 集群拓扑：TiDB（16 vCPU，32 GiB）\* 1 + TiKV（16 vCPU，32 GiB）\* 3
- 数据集：YCSB 非聚簇表，包含 1000 万行（约 10 GiB 数据）。在某些测试中选择性地移除主键，以隔离和评估热点模式的影响。
- 工作负载：包括 `INSERT`、`UPDATE` 和 `DELETE` 的 DML 操作。

### 测试结果

执行速度提高 2 倍，TiDB 最大内存使用量降低 50%，TiKV 写入流变得更加平稳。

- 延迟（秒）

    | 工作负载（10 GiB） | 标准 DML | 流水线 DML | 改进 |
    | --- |  --- |  --- |  --- |
    | YCSB-insert-10M | 368 | 159 | 131.45% |
    | YCSB-update-10M | 255 | 131 | 94.66% |
    | YCSB-delete-10M | 136 | 42 | 223.81% |

- TiDB 内存使用峰值（GiB）

    | 工作负载（10 GiB） | 标准 DML | 流水线 DML | 降低 |
    | --- |  --- |  --- |  --- |
    | YCSB-insert-10M | 25.8 | 12 | 53.49% |
    | YCSB-update-10M | 23.1 | 12.9 | 44.16% |
    | YCSB-delete-10M | 10.1 | 8.08 | 20.00% |

## TiKV 扩展性能

### 挑战

水平扩展是 TiKV 的核心能力，使系统能够根据需要进行扩容或缩容。随着业务需求增长和租户数量增加，TiDB 集群在数据库、表和数据量方面都经历快速增长。快速扩展 TiKV 节点成为维持服务质量的关键。

在某些场景中，TiDB 托管大量数据库和表。当这些表较小或为空时，特别是当表的数量增长到较大规模（如 100 万或更多）时，TiKV 会累积大量微小的 Region。这些小 Region 带来了巨大的维护负担，增加了资源开销，降低了效率。

### 解决方案

为了解决这个问题，TiDB v8.5.0 改进了合并小 Region 的性能，减少了内部开销并提高了资源利用率。此外，TiDB v8.5.0 还包括其他几项增强功能，进一步改进了 TiKV 扩展性能。

### 测试环境

#### 合并小 Region

- 集群拓扑：TiDB（16 vCPU，32 GiB）\* 1 + TiKV（16 vCPU，32 GiB）\* 3
- 数据集：近 100 万个小表，每个表大小 < 2 MiB
- 工作负载：自动合并小 Region

#### 扩展 TiKV 节点

- 集群拓扑：TiDB（16 vCPU，32 GiB）\* 1 + TiKV（16 vCPU，32 GiB）\* 4
- 数据集：20,000 个仓库的 TPC-C 数据集
- 工作负载：将 TiKV 节点从 4 个扩展到 7 个

### 测试结果

小 Region 合并速度提高约 10 倍。

| 指标 | 未改进 | 改进后 |
| --- |  --- |  --- |
| Region 合并持续时间（小时） | 20 | 2 |

TiKV 扩展性能提高超过 40%，TiKV 节点扩容持续时间减少 30%。

| 指标 | 未改进 | 改进后 |
| --- |  --- |  --- |
| TiKV 扩容持续时间（小时） | 5 | 3.5 |

## 基准测试

除了上述测试数据外，你还可以参考以下 v8.5.0 性能的基准测试结果：

- [TPC-C 性能测试报告](/tidb-cloud/v8.5-performance-benchmarking-with-tpcc.md)
- [Sysbench 性能测试报告](/tidb-cloud/v8.5-performance-benchmarking-with-sysbench.md)
